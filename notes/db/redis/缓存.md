## 本地缓存

1. 导入依赖
2. 配置redis主机地址
3. 自动注入RedisTemplate
4. 使用RedisTemplate的方法将缓存放到数据库



## 缓存问题

- 缓存穿透：缓存和数据库都没有的数据被大量请求，导致数据库压力过大
  - 解决方案：缓存空对象、布隆过滤器
- 缓存雪崩：缓存在某一时刻大量失效，请求全部转发到数据库，导致数据库压力过大
  - 解决方案：过期时间设置随机部分、设置热点数据永不过期、降级熔断
- 缓存击穿：并发的查询同一条  缓存中没有（缓存到期）但数据库中有 的数据，同时查询数据库导致击穿
  - 解决方案：设置热点数据永不过期、互斥锁
  - 可以选择加锁，竞争到锁后，确认缓存中是否有数据，没有的情况下再查数据库，然后加入缓存，解锁。

> 雪崩是：不同数据过期
>
> 击穿是：某条热点数据过期



## 分布式缓存

> 本地缓存的问题所在：每个微服务都要有缓存，然而缓存的数据可能不一致

### 分布式锁

分布式的项目，本地锁只能锁住当前服务，所以需要分布式锁。

> 分布式锁的过程：
>
> - 没获得锁 -> 阻塞或者sleep一会   （或者自旋？）
> - 加锁，但解锁之前服务挂掉，没有执行解锁的逻辑，造成死锁
>   - 解决方法：设置过期时间，时间到了自动解锁
> - 业务没有执行完的时候锁过期了，其它线程拿到了锁，本进程执行完之后，将其他进程的锁删了
>   - 解决方法：锁续期（Redisson有看门狗），删锁的时候确认是自己的锁（对锁加上UUID）
> - 确认是自己的锁，但在将要删除的时候锁过期了换了别人的锁，即想要删除的时候锁被掉包了
>   - 解决方法：删除锁的时候必须保证原子性（判断锁和删锁是原子的），使用redis+Lua脚本完成，脚本是原子的。但比较麻烦，所以可以考虑使用现有框架，比如Redisson。

### Redisson

1. 导入依赖

   ```xml
   <!- 练习使用，更推荐使用redisson-spring-boot-starter ->
   <dependency>
       <groupId>org.redisson</groupId>
       <artifactId>redisson</artifactId>
       <version>3.13.4</version>
   </dependency>
   ```

2. 开启配置

   ```java
   @Configuration
   public class MyRedisConfig {
   
       @Value("${ipAddr}")
       private String ipAddr;
   
       // redission通过redissonClient对象使用 // 如果是多个redis集群，可以配置
       @Bean(destroyMethod = "shutdown")
       public RedissonClient redisson() {
           Config config = new Config();
           // 创建单例模式的配置
           config.useSingleServer().setAddress("redis://" + ipAddr + ":6379");
           return Redisson.create(config);
       }
   }
   ```

   

3. 注入RedissonClient

   ```java
   private RedissonClient redissonClient;
   ```

   

4. 使用方法进行加锁、解锁

   ```java
   RLock lock = redissonClient.getLock("锁名称，尽量保持唯一性，所以可以写的具体一点")；
   lock.lock(); //阻塞等待，内为死循环
   lock.unlock();	//推荐放入到finally。如果解锁之前，程序宕机也没关系，因为Redisson有看门狗
   ```

   > 看门狗：在业务执行完之前，不断延长锁的有效期。默认情况下，锁的超时时间是30s，而看门狗会在时间过去三分之一的时候，即剩余20s的时候将锁的有效期延长成为30s。这个期限可以通过Config.lockWatchdoyTimeout来另行修改。

5. `推荐用法`：自己指定锁时间，时间长点即可

   ```java
   lock.lock(10, TimeUnit.SECONDS);	//指定过期时间后，超时自动解锁，看门狗不会延长锁的有效期。
   lock.tryLock(100, 10, TimeUnit.SECONDS);	//尝试加锁，不会阻塞等待。最多等待100秒，10秒后自动解锁
   //内部逻辑：
   //如果设置了锁的超时时间，就执行脚本占锁，
   //如果没设置锁的超时时间，使用开门狗的时间去占锁，然后根据进程id判断线程没结束？就调用看门狗的定时任务，重新给锁设置过期时间。
   //定时任务的周期为：锁时间 / 3 
   
   /**
   *基于Redis的Redisson分布式可重入读写锁RReadWriteLock Java对象实现了java.util.concurrent.locks.ReadWriteLock接口。其中读锁和写锁都继承了RLock接口。
   分布式可重入读写锁允许同时有多个读锁和一个写锁处于加锁状态。
   */
   RReadWriteLock rwlock = redisson.getReadWriteLock("anyRWLock");
   // 最常见的使用方法
   rwlock.readLock().lock();
   // 或
   rwlock.writeLock().lock();
   // 10秒钟以后自动解锁
   // 无需调用unlock方法手动解锁
   rwlock.readLock().lock(10, TimeUnit.SECONDS);
   // 或
   rwlock.writeLock().lock(10, TimeUnit.SECONDS);
   
   // 尝试加锁，最多等待100秒，上锁以后10秒自动解锁
   boolean res = rwlock.readLock().tryLock(100, 10, TimeUnit.SECONDS);
   // 或
   boolean res = rwlock.writeLock().tryLock(100, 10, TimeUnit.SECONDS);
   ```

### 分布式信号量Semaphore

> RLock对象完全符合Java的Lock规范，即只有拥有锁的进程才能解锁，如果其他进程尝试解锁会抛出IllegalMonitorStateException的异常。如果需要其他进程也能解锁，可以使用分布式信号量Semaphore。

> 信号量为存储在redis中的一个数字，当这个数字大于0时，即可以调用`acquire()`方法减少数量，也可以调用`release()`方法增加数量，但是当调用`release()`之后小于0的话方法就会阻塞，直到数字大于0

```java
RSemaphore semaphore = redisson.getSemaphore("semaphore");
semaphore.acquire();
//或
semaphore.acquireAsync();
semaphore.acquire(23);
semaphore.tryAcquire();
//或
semaphore.tryAcquireAsync();
semaphore.tryAcquire(23, TimeUnit.SECONDS);
//或
semaphore.tryAcquireAsync(23, TimeUnit.SECONDS);
semaphore.release(10);
semaphore.release();
//或
semaphore.releaseAsync();
```



### 闭锁（CountDownLatch）

> 基于Redisson的Redisson分布式闭锁CountDownLatch，Java对象`RCountDownLatch`采用了与`java.util.concurrent.CountDownLatch`相似的接口和用法。

> 只有在某个方法调用了n次之后，另一个方法才能执行。比如商品被卖了100次，调用卖完了这个方法。

```java
public void lockDoor(){
    RCountDownLatch latch = redisson.getCountDownLatch("anyCountDownLatch");
    latch.trySetCount(10);
    latch.await();
}

public void gogo(){
    RCountDownLatch latch = redisson.getCountDownLatch("anyCountDownLatch");
    latch.countDown();		//只有lockDoor被调用了10次，这个gogo方法才能执行完
}
```

### 缓存和数据库一致性问题

- 双写模式：写数据库后，写缓存
  - 问题：并发时，2写进入，写完DB后都写缓存，1写完库，2写完库，2写缓存，1写缓存，有暂时的脏数据
- 失效模式：写完数据库后，删缓存
  - 问题：1写完删完，2正在写，此时3开始读，只能读到1，而3读到1之后，2把缓存删了，3把1更新到缓存
  - 解决：缓存设置过期时间，定期更新
  - 解决：写数据写时，加分布式的读写锁。

> 解决方案：
>
> - 如果是用户纬度数据（订单数据、用户数据），这种并发几率非常小，不用考虑这个问题，缓存数据加上过期时间，每隔一段时间触发读的主动更新即可
> - 如果是菜单，商品介绍等基础数据，也可以去使用canal订阅binlog的方式（数据更新后canal得到日志的消息去更新缓存）
>   缓存数据+过期时间也足够解决大部分业务对于缓存的要求。
> - 通过加锁保证并发读写，写写的时候按顺序排好队。读读无所谓。所以适合使用读写锁。（业务不关心脏数据，允许临时脏数据可忽略）
>
> 总结：我们`能放入缓存的数据本就不应该是实时性、一致性要求超高的`。所以缓存数据的时候加上过期时间，保证每天拿到当前最新数据即可。我们`不应该过度设计，增加系统的复杂性`。遇到`实时性、一致性要求高的数据，就应该查数据库`，即使慢点。